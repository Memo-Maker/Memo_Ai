from pytube import YouTube
import re
import os
import json
import whisper
import time
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema.document import Document
from langchain.chains.mapreduce import MapReduceChain
from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain
from langchain.chat_models import ChatOpenAI
from langchain.chains.llm import LLMChain
from langchain.prompts import PromptTemplate
from langchain.chains.combine_documents.stuff import StuffDocumentsChain
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ ê°€ì ¸ì˜¤ê¸°
API_KEY = os.getenv("OPENAI_API_KEY")

def process_youtube_url(url):
    try:
        print("ğŸŸ¢ ì˜ìƒ ìš”ì•½ ì‹œì‘")

        # YouTube ê°ì²´ ìƒì„±
        yt = YouTube(url)

        # í´ë” ê²½ë¡œ ì„¤ì •
        output_folder = os.path.join('./assets', 'audio')
        os.makedirs(output_folder, exist_ok=True)  # ë§Œì•½ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±

        # íŒŒì¼ëª…ìœ¼ë¡œ í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë¬¸ì ì œê±° ë° ê³µë°± ëŒ€ì²´
        cleaned_title = re.sub(r'[^\w\s-]', '', yt.title).strip().replace(' ', '_')

        # ì¸ë„¤ì¼ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        thumbnail_url = yt.thumbnail_url

        # ì˜ìƒì˜ ê¸¸ì´(ì´ˆ) ê°€ì ¸ì˜¤ê¸°
        video_length_seconds = yt.length

        # ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
        audio_file_path = os.path.join(output_folder, cleaned_title + '.mp3')
        yt.streams.filter(only_audio=True).first().download(
            output_path=output_folder, filename=cleaned_title + '.mp3'
        )

        # JSON data (video title, URL, and thumbnail URL)
        data = {
            cleaned_title :{
                'title': yt.title,
                "url": url,
                "thumbnail_url": thumbnail_url,
                "video_duration" : video_length_seconds
            }
        }

        json_file_path = os.path.join('assets', 'audio_urls.json')

        # JSON íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë°ì´í„° ì¶”ê°€
        if os.path.exists(json_file_path):
            with open(json_file_path, 'r', encoding='utf-8') as f:  # UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì—´ê¸°
                existing_data = json.load(f)
            existing_data.update(data)
            data = existing_data

        with open(json_file_path, 'w', encoding='utf-8') as f:  # UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì“°ê¸°
            json.dump(data, f, indent=4, ensure_ascii=False)

        print("ğŸ”µ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ")

        audio_file_name = f"{cleaned_title}.mp3"
        additional_path = r"assets\audio"  # ì¶”ê°€ì ì¸ ê²½ë¡œ

        # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        # script_directoryëŠ” í˜„ì¬ íŒŒì´ì¬ í”„ë¡œì íŠ¸ê°€ ìˆëŠ” ìœ„ì¹˜ë¥¼ ë§í•¨
        script_directory = os.path.dirname(os.path.abspath(__file__))
        MEMO_AI_directory = os.path.dirname(script_directory)

        # ê²½ë¡œë¥¼ ì¡°ë¦½í•´ì„œ ì˜¤ë””ì˜¤íŒŒì¼ ê²½ë¡œë¡œ ë§Œë“¦
        audio_file_path = os.path.join(MEMO_AI_directory, additional_path, audio_file_name)
        print(f" -->> ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ : {audio_file_path}")

        # Langchain ëª¨ë¸ ë° map-reduce ì²´ì¸ ì„¤ì •
        llm = ChatOpenAI(temperature=1, openai_api_key=API_KEY)

        # text_splitter ì„¤ì •
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=50,
            length_function=len,
        )

        # Map prompt
        map_template = """The following is a set of documents
        {docs}
        Based on this list of docs, please identify the main themes
        Helpful Answer:"""

        map_prompt = PromptTemplate.from_template(map_template)

        # Reduce prompt
        reduce_template = """The following is set of summaries:
        {doc_summaries}
        Take these and distill it into a final, consolidated summary of the main themes.
        The final answer is a single paragraph of about 200 words and must be in Korean.
        Helpful Answer:"""

        reduce_prompt = PromptTemplate.from_template(reduce_template)

        # Reduce chain
        reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)
        combine_documents_chain = StuffDocumentsChain(
            llm_chain=reduce_chain, document_variable_name="doc_summaries"
        )
        reduce_documents_chain = ReduceDocumentsChain(
            combine_documents_chain=combine_documents_chain,
            token_max=4000,
        )

        # Map chain
        map_chain = LLMChain(llm=llm, prompt=map_prompt)

        # Map-reduce chain ì„¤ì •
        map_reduce_chain = MapReduceDocumentsChain(
            llm_chain=map_chain,
            reduce_documents_chain=reduce_documents_chain,
            document_variable_name="docs",
            return_intermediate_steps=False,
        )

    
        print("ğŸŸ¢ speechToTextLocal ì‹œì‘")
        start_time = time.time()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        
        if not os.path.exists(audio_file_path):
            raise FileNotFoundError("ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # tiny, base, small, medium, large
        model = whisper.load_model('base')
        result = model.transcribe(audio_file_path)
        print(result['text'])
        
        print("ğŸ”µ" + str(len(result['text'])) + "ì")

        # text_split
        docs = [Document(page_content=x) for x in text_splitter.split_text(result["text"])]
        split_docs = text_splitter.split_documents(docs)
        print(f" ğŸ”µsplit_docs : {len(split_docs)} ê°œ")

        # ë‚´ìš© ìš”ì•½ ì‹œì‘
        sum_result = map_reduce_chain.run(split_docs)

        print(sum_result)
        
        end_time = time.time()  # ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
        elapsed_time = end_time - start_time  # ì „ì²´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        print(f"ğŸ”µ í”„ë¡œê·¸ë¨ ì†Œìš” ì‹œê°„: {elapsed_time:.2f} ì´ˆ")  # ì‹¤í–‰ ì‹œê°„ ì¶œë ¥

    except FileNotFoundError as e:
        print(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    return sum_result

if __name__ == "__main__":
    url = input("URL ì…ë ¥ : ")
    process_youtube_url(url)
